{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhatiaparteek/ml_with_python/blob/main/CNN_DogsvsCats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Snippet to mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyynNhyiHEc_",
        "outputId": "01240eca-ffe0-4dee-c13f-4c1989b82572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers  import MaxPooling2D\n",
        "from keras.layers  import Flatten\n",
        "from keras.layers  import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "j-TfmxuyHGs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialising the CNN\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "6wM88LOelAQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convolution\n",
        "\n",
        "#classifier.add(Conv2D(filters=32, kernel_size=3,  activation='relu' ,  input_shape=[128,  128,  3]))\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (128, 128, 3), activation = 'relu'))\n",
        "\n"
      ],
      "metadata": {
        "id": "nyeoSAXrl5Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling\n",
        "#classifier.add(MaxPooling2D(pool_size=2, strides=2) )\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "metadata": {
        "id": "nFykLLk_mJLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening\n",
        "classifier.add(Flatten())"
      ],
      "metadata": {
        "id": "F-lZVDeNmRIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Full Connection\n",
        "classifier.add(Dense(units=128,  activation='relu'))"
      ],
      "metadata": {
        "id": "Ce-4J0q1mXyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output Layer\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "nlBJ1A8emvuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics =  ['accuracy' ])"
      ],
      "metadata": {
        "id": "wxDhZ6C-nJWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "rescale=1. /255,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True)"
      ],
      "metadata": {
        "id": "3gANO1NNncVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/dogs-vs-cats/train' ,\n",
        "                                target_size=(128, 128) ,\n",
        "                                batch_size=32,\n",
        "                                class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzayinTHnqoI",
        "outputId": "815b765a-1fe8-494e-fb71-96f1b83a1d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Image Augmentation of Test Data\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "67u4kw0Sn37w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(\"/content/drive/MyDrive/dogs-vs-cats/test\",\n",
        "                                          target_size = (128, 128),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode=\"binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RJ7YUjXw9ci",
        "outputId": "ee51ede3-aa83-43ec-8d66-e9808a1fb340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the CNN on the training set and evaluating it on test set\n",
        "classifier.fit(training_set,\n",
        "                        steps_per_epoch=100,\n",
        "                         epochs=50,\n",
        "                         validation_data=test_set,\n",
        "                         validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amV86mglw_jr",
        "outputId": "51125347-8843-4747-8368-50bebc03d6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 88s 861ms/step - loss: 0.9071 - accuracy: 0.5753 - val_loss: 0.6334 - val_accuracy: 0.6656\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 65s 651ms/step - loss: 0.6304 - accuracy: 0.6494 - val_loss: 0.5420 - val_accuracy: 0.7031\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 55s 555ms/step - loss: 0.5936 - accuracy: 0.6812 - val_loss: 0.5882 - val_accuracy: 0.6625\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 48s 472ms/step - loss: 0.5825 - accuracy: 0.7038 - val_loss: 0.5883 - val_accuracy: 0.6812\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 45s 457ms/step - loss: 0.5694 - accuracy: 0.6947 - val_loss: 0.6534 - val_accuracy: 0.6125\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 37s 364ms/step - loss: 0.5680 - accuracy: 0.7038 - val_loss: 0.6687 - val_accuracy: 0.6531\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 37s 374ms/step - loss: 0.5504 - accuracy: 0.7147 - val_loss: 0.5360 - val_accuracy: 0.7437\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.5304 - accuracy: 0.7372 - val_loss: 0.5148 - val_accuracy: 0.7281\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 31s 312ms/step - loss: 0.5530 - accuracy: 0.7163 - val_loss: 0.5406 - val_accuracy: 0.6875\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.5275 - accuracy: 0.7362 - val_loss: 0.5224 - val_accuracy: 0.7281\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.5268 - accuracy: 0.7283 - val_loss: 0.5231 - val_accuracy: 0.7250\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 31s 310ms/step - loss: 0.5234 - accuracy: 0.7365 - val_loss: 0.4938 - val_accuracy: 0.7531\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.5109 - accuracy: 0.7453 - val_loss: 0.5381 - val_accuracy: 0.7094\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.5125 - accuracy: 0.7494 - val_loss: 0.5236 - val_accuracy: 0.7563\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.5035 - accuracy: 0.7519 - val_loss: 0.5372 - val_accuracy: 0.7531\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 31s 305ms/step - loss: 0.5042 - accuracy: 0.7541 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.4931 - accuracy: 0.7613 - val_loss: 0.5385 - val_accuracy: 0.7312\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.4915 - accuracy: 0.7601 - val_loss: 0.5446 - val_accuracy: 0.7563\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5435 - val_accuracy: 0.7375\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.4878 - accuracy: 0.7647 - val_loss: 0.5628 - val_accuracy: 0.7250\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.4819 - accuracy: 0.7681 - val_loss: 0.5013 - val_accuracy: 0.7969\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.4686 - accuracy: 0.7694 - val_loss: 0.5288 - val_accuracy: 0.7469\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.4594 - accuracy: 0.7803 - val_loss: 0.4646 - val_accuracy: 0.7812\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.5267 - val_accuracy: 0.7563\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.4491 - accuracy: 0.7908 - val_loss: 0.5725 - val_accuracy: 0.7469\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.4606 - accuracy: 0.7903 - val_loss: 0.5758 - val_accuracy: 0.7500\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.4403 - accuracy: 0.7836 - val_loss: 0.5220 - val_accuracy: 0.7563\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.4377 - accuracy: 0.7965 - val_loss: 0.5215 - val_accuracy: 0.7781\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 0.4492 - accuracy: 0.7834 - val_loss: 0.5487 - val_accuracy: 0.7406\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.4417 - accuracy: 0.7905 - val_loss: 0.5152 - val_accuracy: 0.7719\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.4334 - accuracy: 0.7987 - val_loss: 0.5208 - val_accuracy: 0.7406\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.4299 - accuracy: 0.7991 - val_loss: 0.4728 - val_accuracy: 0.7781\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 30s 296ms/step - loss: 0.4166 - accuracy: 0.8106 - val_loss: 0.5100 - val_accuracy: 0.7625\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.4182 - accuracy: 0.8031 - val_loss: 0.5961 - val_accuracy: 0.7719\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.4128 - accuracy: 0.8141 - val_loss: 0.6134 - val_accuracy: 0.7219\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.4058 - accuracy: 0.8125 - val_loss: 0.5480 - val_accuracy: 0.7656\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 30s 305ms/step - loss: 0.4195 - accuracy: 0.8156 - val_loss: 0.4375 - val_accuracy: 0.7781\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.3896 - accuracy: 0.8191 - val_loss: 0.4947 - val_accuracy: 0.7719\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 31s 312ms/step - loss: 0.4064 - accuracy: 0.8156 - val_loss: 0.4895 - val_accuracy: 0.7812\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.3995 - accuracy: 0.8122 - val_loss: 0.4719 - val_accuracy: 0.7875\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.4030 - accuracy: 0.8109 - val_loss: 0.4749 - val_accuracy: 0.8000\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.3686 - accuracy: 0.8409 - val_loss: 0.4827 - val_accuracy: 0.7531\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.3986 - accuracy: 0.8209 - val_loss: 0.4817 - val_accuracy: 0.7781\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.3604 - accuracy: 0.8413 - val_loss: 0.4648 - val_accuracy: 0.8125\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 31s 307ms/step - loss: 0.3638 - accuracy: 0.8378 - val_loss: 0.6394 - val_accuracy: 0.7688\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.3740 - accuracy: 0.8364 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.3828 - accuracy: 0.8325 - val_loss: 0.5199 - val_accuracy: 0.7406\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.3523 - accuracy: 0.8486 - val_loss: 0.4794 - val_accuracy: 0.7906\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.3479 - accuracy: 0.8496 - val_loss: 0.5939 - val_accuracy: 0.7406\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.3682 - accuracy: 0.8334 - val_loss: 0.5387 - val_accuracy: 0.7969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb498f879d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a single prediction\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "unseen_image = image.load_img(\"/content/sample_data/415.jpg\",                                                             target_size = (128, 128))\n",
        "unseen_image  = image.img_to_array(unseen_image)"
      ],
      "metadata": {
        "id": "t_gRB6NKxCRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_image  = np.expand_dims(unseen_image,  axis  = 0)\n",
        "result  =  classifier.predict(unseen_image)\n",
        "training_set.class_indices\n",
        "if  result[0] [0]  ==1:\n",
        "            prediction  = \"dog\"\n",
        "else :\n",
        "            prediction  = \"cat\"\n",
        "print (\"The given image is of \"+prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGgblCIxxLhl",
        "outputId": "6ee46eb1-b68c-45d5-b2c3-a5339e5b6631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given image is of dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras. preprocessing.image import ImageDataGenerator\n",
        "#Initialising the CNN\n",
        "classifier = Sequential()\n",
        "#Convolution\n",
        "classifier.add(Conv2D(filters=32,  kernel_size=3,  activation=\"relu\"))\n",
        "#Pooling\n",
        "classifier.add(MaxPooling2D(pool_size=2,  strides=2))\n",
        "#Adding second convolution layer\n",
        "classifier.add(Conv2D(filters=32,  kernel_size=3,  activation=\"relu\"))\n",
        "#Adding second pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size=2,  strides=2))\n",
        "#Flattening\n",
        "classifier.add (Flatten())\n",
        "#Full Connection\n",
        "classifier.add(Dense(units=128,  activation=\"relu\"))\n",
        "#Output Layer\n",
        "classifier.add(Dense(units=1,  activation=\"sigmoid\"))\n",
        "#Compiling the CNN\n",
        "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\" ,metrics =  ['accuracy' ])\n",
        "#Image Augmentation\n",
        "train_datagen=ImageDataGenerator (rescale=1./255,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True)\n",
        "training_set= train_datagen.flow_from_directory(\"/content/drive/MyDrive/dogs-vs-cats/train\",\n",
        "                                target_size=(128, 128) ,\n",
        "                                batch_size=32,\n",
        "                                class_mode=\"binary\")#Image Augmentation of Test Data\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\"/content/drive/MyDrive/dogs-vs-cats/test\",\n",
        "                                          target_size = (128, 128),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode=\"binary\")   #Training the CNN on the training set and evaluating it on test set\n",
        "classifier.fit(training_set,\n",
        "                 steps_per_epoch=100,\n",
        "                 epochs=50,\n",
        "                 validation_data=test_set,validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceCjwrxVxQ0o",
        "outputId": "270c52e3-9fd0-469e-c531-37e42971c780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - 35s 339ms/step - loss: 0.7665 - accuracy: 0.5415 - val_loss: 0.6898 - val_accuracy: 0.5094\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.6770 - accuracy: 0.5863 - val_loss: 0.6680 - val_accuracy: 0.5844\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.6275 - accuracy: 0.6652 - val_loss: 0.6987 - val_accuracy: 0.6031\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.6122 - accuracy: 0.6619 - val_loss: 0.6135 - val_accuracy: 0.6438\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.5934 - accuracy: 0.6769 - val_loss: 0.5543 - val_accuracy: 0.7031\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.5849 - accuracy: 0.7016 - val_loss: 0.5815 - val_accuracy: 0.6812\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.5611 - accuracy: 0.7073 - val_loss: 0.5342 - val_accuracy: 0.7000\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.5445 - accuracy: 0.7133 - val_loss: 0.5409 - val_accuracy: 0.7125\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.5481 - accuracy: 0.7230 - val_loss: 0.6428 - val_accuracy: 0.6844\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.5544 - accuracy: 0.7259 - val_loss: 0.6023 - val_accuracy: 0.6750\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.5401 - accuracy: 0.7264 - val_loss: 0.5369 - val_accuracy: 0.7063\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.5149 - accuracy: 0.7431 - val_loss: 0.5170 - val_accuracy: 0.7188\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.5282 - accuracy: 0.7387 - val_loss: 0.5142 - val_accuracy: 0.7250\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 31s 312ms/step - loss: 0.4900 - accuracy: 0.7619 - val_loss: 0.4593 - val_accuracy: 0.7750\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.4888 - accuracy: 0.7635 - val_loss: 0.4050 - val_accuracy: 0.8250\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.4809 - accuracy: 0.7657 - val_loss: 0.5782 - val_accuracy: 0.7031\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.4893 - accuracy: 0.7666 - val_loss: 0.5761 - val_accuracy: 0.7188\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.4579 - accuracy: 0.7844 - val_loss: 0.4326 - val_accuracy: 0.7844\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.4626 - accuracy: 0.7738 - val_loss: 0.4080 - val_accuracy: 0.8062\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.4461 - accuracy: 0.7906 - val_loss: 0.4896 - val_accuracy: 0.7875\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.4442 - accuracy: 0.7862 - val_loss: 0.5015 - val_accuracy: 0.7594\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.4290 - accuracy: 0.8044 - val_loss: 0.4653 - val_accuracy: 0.7719\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.4521 - accuracy: 0.7842 - val_loss: 0.4628 - val_accuracy: 0.7656\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.4362 - accuracy: 0.7981 - val_loss: 0.4499 - val_accuracy: 0.7937\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 30s 305ms/step - loss: 0.4380 - accuracy: 0.8031 - val_loss: 0.5045 - val_accuracy: 0.7781\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.4168 - accuracy: 0.8037 - val_loss: 0.4142 - val_accuracy: 0.8281\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.3970 - accuracy: 0.8288 - val_loss: 0.4150 - val_accuracy: 0.8000\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.4036 - accuracy: 0.8156 - val_loss: 0.3861 - val_accuracy: 0.8031\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.4010 - accuracy: 0.8238 - val_loss: 0.4466 - val_accuracy: 0.7906\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.3852 - accuracy: 0.8334 - val_loss: 0.3683 - val_accuracy: 0.8375\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.3918 - accuracy: 0.8144 - val_loss: 0.4576 - val_accuracy: 0.7844\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.3890 - accuracy: 0.8238 - val_loss: 0.5616 - val_accuracy: 0.7531\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.3903 - accuracy: 0.8285 - val_loss: 0.4160 - val_accuracy: 0.8062\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.3773 - accuracy: 0.8297 - val_loss: 0.4131 - val_accuracy: 0.8250\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.3660 - accuracy: 0.8316 - val_loss: 0.4108 - val_accuracy: 0.8281\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.3545 - accuracy: 0.8422 - val_loss: 0.4305 - val_accuracy: 0.8156\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 31s 305ms/step - loss: 0.3492 - accuracy: 0.8472 - val_loss: 0.4846 - val_accuracy: 0.7906\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.3682 - accuracy: 0.8345 - val_loss: 0.3880 - val_accuracy: 0.8313\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 30s 300ms/step - loss: 0.3735 - accuracy: 0.8384 - val_loss: 0.4004 - val_accuracy: 0.8281\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.3386 - accuracy: 0.8438 - val_loss: 0.4988 - val_accuracy: 0.7719\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.3178 - accuracy: 0.8622 - val_loss: 0.5495 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.3465 - accuracy: 0.8427 - val_loss: 0.4534 - val_accuracy: 0.7844\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.3222 - accuracy: 0.8603 - val_loss: 0.4972 - val_accuracy: 0.7688\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.3076 - accuracy: 0.8684 - val_loss: 0.4734 - val_accuracy: 0.7937\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.3272 - accuracy: 0.8491 - val_loss: 0.4329 - val_accuracy: 0.8156\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.3208 - accuracy: 0.8587 - val_loss: 0.4629 - val_accuracy: 0.8062\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 31s 308ms/step - loss: 0.2964 - accuracy: 0.8747 - val_loss: 0.4298 - val_accuracy: 0.8313\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.3137 - accuracy: 0.8625 - val_loss: 0.4157 - val_accuracy: 0.8281\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 30s 305ms/step - loss: 0.2872 - accuracy: 0.8763 - val_loss: 0.5302 - val_accuracy: 0.7656\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.3011 - accuracy: 0.8737 - val_loss: 0.4368 - val_accuracy: 0.8031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb497918050>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unseen_image = image.load_img(\"/content/sample_data/415.jpg\",target_size = (128, 128))\n",
        "unseen_image=image.img_to_array(unseen_image)\n",
        "unseen_image  = np.expand_dims(unseen_image,  axis  = 0)\n",
        "result  =  classifier.predict(unseen_image)\n",
        "training_set.class_indices\n",
        "if  result[0] [0]  ==1:\n",
        "            prediction  = \"dog\"\n",
        "else :\n",
        "            prediction  = \"cat\"\n",
        "print (\"The given image is of \"+prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbWjeYEixZgg",
        "outputId": "d43d888f-e261-427a-b7ba-009144a62405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given image is of dog\n"
          ]
        }
      ]
    }
  ]
}