{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhatiaparteek/ml_with_python/blob/main/chapter_4_preprocessing/pre-processing-of-data\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgPKJs_799tH"
      },
      "source": [
        "1. Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtmDpSq7qfyd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# style 1\n",
        "import matplotlib.pyplot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Used to perform scaling of data under pre-processing phase.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Used to split the dataset into training and testing.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Used to perform Linear regression.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Used to perform performance analysis of classifier by making a confusion matrix."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDUTwScz-n1v"
      },
      "source": [
        "\n",
        "2. Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_krp_iwznlp"
      },
      "source": [
        "#----------------------------------Reading the dataset-----------------------\n",
        "dataset = pd.read_csv('salary.csv')\n",
        "# pd is the alias of the Pandas library imported.\n",
        "X = dataset.iloc[:, :-1].values\n",
        "Y = dataset.iloc[:,3].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wY7ULEDB6bW"
      },
      "source": [
        "\n",
        "3. Taking care of missing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM9IfLA0B9d5",
        "outputId": "f9ba84ff-c470-442f-bcab-cd2dd38769ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# handling of missing data\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "imputer = imputer.fit(X[:,1:3])\n",
        "X[:,1:3] = imputer.transform(X[:,1:3])\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Hyderabad' 44.0 72000.0]\n",
            " ['Mumbai' 27.0 48000.0]\n",
            " ['Delhi' 30.0 54000.0]\n",
            " ['Mumbai' 38.0 61000.0]\n",
            " ['Delhi' 40.0 63777.77777777778]\n",
            " ['Hyderabad' 35.0 58000.0]\n",
            " ['Mumbai' 38.77777777777778 52000.0]\n",
            " ['Hyderabad' 48.0 79000.0]\n",
            " ['Delhi' 50.0 83000.0]\n",
            " ['Hyderabad' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHCnzaq0CFun"
      },
      "source": [
        "4. Encoding categorical data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr3oQustGRke",
        "outputId": "405661d5-4d47-45da-c16f-1280a2095fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#label encoding categorical attribute city\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelEncoder_X = LabelEncoder()\n",
        "X[:, 0] = labelEncoder_X.fit_transform(X[:, 0])\n",
        "print(X[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 0 2 0 1 2 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. One-hot encoding on categorical data"
      ],
      "metadata": {
        "id": "4Uf6lazB4sLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encoding categorical attribute city\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)\n",
        "#Alternate way to do One-hot encoding is mentioned in the end of this file"
      ],
      "metadata": {
        "id": "hiu-GeSU4lw-",
        "outputId": "cfd2d6d2-5833-4c10-ca69-23fef697fdeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 40.0 63777.77777777778]\n",
            " [0.0 1.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 48.0 79000.0]\n",
            " [1.0 0.0 0.0 50.0 83000.0]\n",
            " [0.0 1.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Lable encoding on purchased attribute"
      ],
      "metadata": {
        "id": "d3K-f_bW5Ceo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoding purchased attribute\n",
        "labelEncoder_Y = LabelEncoder()\n",
        "Y = labelEncoder_Y.fit_transform(Y)\n",
        "print(Y)"
      ],
      "metadata": {
        "id": "24VX8DNV5KkW",
        "outputId": "ed8bc172-7d0b-47e9-dc86-f0b5acf68a0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcwi2CU4GTlW"
      },
      "source": [
        "7. Splitting of Dataset into training and testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1MmI-62GYf6",
        "outputId": "83d54aeb-831f-4368-b702-45045de0b612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Splitting of Dataset into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(Y_train)\n",
        "print(Y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 40.0 63777.77777777778]\n",
            " [0.0 1.0 0.0 37.0 67000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 48.0 79000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 44.0 72000.0]\n",
            " [0.0 1.0 0.0 35.0 58000.0]]\n",
            "[[1.0 0.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 50.0 83000.0]]\n",
            "[1 1 1 0 1 0 0 1]\n",
            "[0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytihsZOrGVzv"
      },
      "source": [
        "#Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJCAFYtzGeOe",
        "outputId": "92ada428-1883-4bd5-9665-417d3459aa72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Feature Scaling\n",
        "from sklearn import preprocessing\n",
        "X_train = preprocessing.normalize(X_train, norm='l1')\n",
        "X_test = preprocessing.normalize(X_test, norm='l1')\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.56693693e-05 0.00000000e+00 0.00000000e+00 6.26774774e-04\n",
            "  9.99357556e-01]\n",
            " [0.00000000e+00 1.49169128e-05 0.00000000e+00 5.51925773e-04\n",
            "  9.99433157e-01]\n",
            " [0.00000000e+00 0.00000000e+00 2.08211876e-05 5.62172066e-04\n",
            "  9.99417007e-01]\n",
            " [0.00000000e+00 0.00000000e+00 1.92160698e-05 7.45156483e-04\n",
            "  9.99235627e-01]\n",
            " [0.00000000e+00 1.26503814e-05 0.00000000e+00 6.07218308e-04\n",
            "  9.99380131e-01]\n",
            " [0.00000000e+00 0.00000000e+00 1.63829683e-05 6.22552794e-04\n",
            "  9.99361064e-01]\n",
            " [0.00000000e+00 1.38802138e-05 0.00000000e+00 6.10729405e-04\n",
            "  9.99375390e-01]\n",
            " [0.00000000e+00 1.72306844e-05 0.00000000e+00 6.03073954e-04\n",
            "  9.99379695e-01]]\n",
            "[[1.85078936e-05 0.00000000e+00 0.00000000e+00 5.55236808e-04\n",
            "  9.99426255e-01]\n",
            " [1.20407942e-05 0.00000000e+00 0.00000000e+00 6.02039711e-04\n",
            "  9.99385919e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIDroYnuGqQX"
      },
      "source": [
        "Standardizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvCqz_JOGqgS",
        "outputId": "895a69b4-b7dc-4cdc-ac0c-f1d40aae34aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Standardizing the data\n",
        "#lets do split again as we have already applied normalization on X_train and X_test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
        "#apply standarization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scale_X = StandardScaler()\n",
        "X_train = scale_X.fit_transform(X_train)\n",
        "X_test = scale_X.transform(X_test)\n",
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.64575131 -1.         -0.77459667  0.26306757  0.12381479]\n",
            " [-0.37796447  1.         -0.77459667 -0.25350148  0.46175632]\n",
            " [-0.37796447 -1.          1.29099445 -1.97539832 -1.53093341]\n",
            " [-0.37796447 -1.          1.29099445  0.05261351 -1.11141978]\n",
            " [-0.37796447  1.         -0.77459667  1.64058505  1.7202972 ]\n",
            " [-0.37796447 -1.          1.29099445 -0.0813118  -0.16751412]\n",
            " [-0.37796447  1.         -0.77459667  0.95182631  0.98614835]\n",
            " [-0.37796447  1.         -0.77459667 -0.59788085 -0.48214934]]\n",
            "[[ 2.64575131 -1.         -0.77459667 -1.45882927 -0.90166297]\n",
            " [ 2.64575131 -1.         -0.77459667  1.98496442  2.13981082]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternate way to do One-hot encoding"
      ],
      "metadata": {
        "id": "pFYk-s-06siC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Alternate way to do One-hot encoding\n",
        "#Importing of desired libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#---------------------------Reading the dataset----------------------\n",
        "dataset = pd.read_csv('salary.csv')\n",
        "# pd is the alias of the Pandas library imported.\n",
        "dataset = pd.get_dummies(dataset, columns=[\"City\"], drop_first=True)\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "g04CxliA52VX",
        "outputId": "876e2d44-033e-467e-b839-d2986e639556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Age   Salary Purchased  City_Hyderabad  City_Mumbai\n",
            "0  44.0  72000.0        No            True        False\n",
            "1  27.0  48000.0       Yes           False         True\n",
            "2  30.0  54000.0        No           False        False\n",
            "3  38.0  61000.0        No           False         True\n",
            "4  40.0      NaN       Yes           False        False\n",
            "5  35.0  58000.0       Yes            True        False\n",
            "6   NaN  52000.0        No           False         True\n",
            "7  48.0  79000.0       Yes            True        False\n",
            "8  50.0  83000.0        No           False        False\n",
            "9  37.0  67000.0       Yes            True        False\n"
          ]
        }
      ]
    }
  ]
}